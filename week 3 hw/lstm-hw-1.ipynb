{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to load the wav file","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport glob\nimport librosa\n\ndata1 = []\nlabels1 = []\nmeta1=[]\n\naorticstenosis = glob.glob('/kaggle/input/15sdataforheartsound/aorticstenosis/*.wav')\nmitral_regurgitation = glob.glob('/kaggle/input/15sdataforheartsound/mitral regurgitation/*.wav')\nmitral_stenosis = glob.glob('/kaggle/input/15sdataforheartsound/mitral stenosis/*.wav')\nmitral_valve_prolapse = glob.glob('/kaggle/input/15sdataforheartsound/mitral valve prolapse/*.wav')\nnormal = glob.glob('/kaggle/input/15sdataforheartsound/normal/*.wav')\n\nSAMPLE_RATE=1000\n\n\nfor file_path in aorticstenosis:   \n    #print(file_path)\n    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n    signal=np.array(signal)\n    data1.append(signal)\n    labels1.append(0)\n\nfor file_path in mitral_regurgitation:   \n   # print(file_path)\n    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n    signal=np.array(signal)\n    data1.append(signal)\n    labels1.append(1)\n    \nfor file_path in mitral_stenosis:   \n   # print(file_path)\n    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n    signal=np.array(signal)\n    data1.append(signal)\n    labels1.append(2)\n    \nfor file_path in mitral_valve_prolapse:   \n   # print(file_path)\n    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n    signal=np.array(signal)\n    data1.append(signal)\n    labels1.append(3)\n    \nfor file_path in normal:   \n   # print(file_path)\n    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n    signal=np.array(signal)\n    data1.append(signal)\n    labels1.append(4)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T14:12:35.431305Z","iopub.execute_input":"2023-07-06T14:12:35.431652Z","iopub.status.idle":"2023-07-06T14:13:06.866072Z","shell.execute_reply.started":"2023-07-06T14:12:35.431622Z","shell.execute_reply":"2023-07-06T14:13:06.864952Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"X= np.array(data1)\ny= np.array(labels1)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T14:14:48.137392Z","iopub.execute_input":"2023-07-06T14:14:48.138203Z","iopub.status.idle":"2023-07-06T14:14:48.148728Z","shell.execute_reply.started":"2023-07-06T14:14:48.138169Z","shell.execute_reply":"2023-07-06T14:14:48.147731Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-06T14:14:50.033073Z","iopub.execute_input":"2023-07-06T14:14:50.033435Z","iopub.status.idle":"2023-07-06T14:14:50.041539Z","shell.execute_reply.started":"2023-07-06T14:14:50.033409Z","shell.execute_reply":"2023-07-06T14:14:50.040379Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(1000, 1125)"},"metadata":{}}]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-06T14:14:52.872981Z","iopub.execute_input":"2023-07-06T14:14:52.873333Z","iopub.status.idle":"2023-07-06T14:14:52.880116Z","shell.execute_reply.started":"2023-07-06T14:14:52.873306Z","shell.execute_reply":"2023-07-06T14:14:52.879185Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(1000,)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nnum_classes = 5\n\n# Perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, tf.keras.utils.to_categorical(y, num_classes), test_size=0.2, random_state=32)\n\n# Perform train-validation split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=32)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T14:32:51.999731Z","iopub.execute_input":"2023-07-06T14:32:52.000094Z","iopub.status.idle":"2023-07-06T14:32:52.012030Z","shell.execute_reply.started":"2023-07-06T14:32:52.000065Z","shell.execute_reply":"2023-07-06T14:32:52.010750Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"640\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\n# Generate synthetic training data\nnum_samples = 1000\ninput_shape = (1125,1)\n\n# Define the LSTM-based model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.LSTM(100, activation= 'relu',input_shape=input_shape, return_sequences= True),\n    tf.keras.layers.LSTM(100),\n    \n    tf.keras.layers.Dense(750, activation='relu'),\n    tf.keras.layers.Dense(500, activation='relu'),\n    tf.keras.layers.Dense(300, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',   # Monitor validation loss for learning rate reduction\n    factor=0.05,            # Reduce learning rate by a factor of 0.1\n    patience=5,            # Number of epochs with no improvement after which learning rate will be reduced\n    min_lr=1e-6            # Minimum learning rate\n)\n\n# Define the model checkpoint callback to save the best model\ncheckpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n\n# Define the early stopping callback to stop training if validation loss does not improve\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=6)\n\n# Train the model\n\nmodel.fit(X_train, y_train,validation_data=(X_val,y_val),epochs=100,batch_size=32,callbacks=[lr_callback,checkpoint_callback,early_stopping_callback])\n\n# Evaluate the model\nbest_model = tf.keras.models.load_model('best_model.h5')\nloss, accuracy = best_model.evaluate(X_test, y_test)\n\nprint(f\"Test loss: {loss:.4f}\")\nprint(f\"Test accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T14:35:14.725899Z","iopub.execute_input":"2023-07-06T14:35:14.726605Z","iopub.status.idle":"2023-07-06T14:47:58.953794Z","shell.execute_reply.started":"2023-07-06T14:35:14.726571Z","shell.execute_reply":"2023-07-06T14:47:58.952750Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/100\n20/20 [==============================] - 25s 1s/step - loss: 1.5799 - accuracy: 0.2391 - val_loss: 1.5828 - val_accuracy: 0.3250 - lr: 0.0010\nEpoch 2/100\n20/20 [==============================] - 21s 1s/step - loss: 1.5081 - accuracy: 0.3281 - val_loss: 1.5287 - val_accuracy: 0.3313 - lr: 0.0010\nEpoch 3/100\n20/20 [==============================] - 20s 985ms/step - loss: 1.4554 - accuracy: 0.3359 - val_loss: 1.5079 - val_accuracy: 0.3375 - lr: 0.0010\nEpoch 4/100\n20/20 [==============================] - 20s 1s/step - loss: 1.4254 - accuracy: 0.3734 - val_loss: 1.5065 - val_accuracy: 0.3125 - lr: 0.0010\nEpoch 5/100\n20/20 [==============================] - 19s 964ms/step - loss: 1.4216 - accuracy: 0.3391 - val_loss: 1.4601 - val_accuracy: 0.3500 - lr: 0.0010\nEpoch 6/100\n20/20 [==============================] - 21s 1s/step - loss: 1.3778 - accuracy: 0.3828 - val_loss: 1.4814 - val_accuracy: 0.3562 - lr: 0.0010\nEpoch 7/100\n20/20 [==============================] - 20s 1s/step - loss: 1.3695 - accuracy: 0.3313 - val_loss: 1.3908 - val_accuracy: 0.3500 - lr: 0.0010\nEpoch 8/100\n20/20 [==============================] - 20s 1s/step - loss: 1.3231 - accuracy: 0.3750 - val_loss: 1.3678 - val_accuracy: 0.3688 - lr: 0.0010\nEpoch 9/100\n20/20 [==============================] - 20s 989ms/step - loss: 1.3085 - accuracy: 0.4031 - val_loss: 1.3479 - val_accuracy: 0.3688 - lr: 0.0010\nEpoch 10/100\n20/20 [==============================] - 21s 1s/step - loss: 1.2974 - accuracy: 0.3969 - val_loss: 1.3617 - val_accuracy: 0.3750 - lr: 0.0010\nEpoch 11/100\n20/20 [==============================] - 20s 981ms/step - loss: 1.2990 - accuracy: 0.4234 - val_loss: 1.3399 - val_accuracy: 0.3625 - lr: 0.0010\nEpoch 12/100\n20/20 [==============================] - 20s 1s/step - loss: 1.3002 - accuracy: 0.4141 - val_loss: 1.3139 - val_accuracy: 0.4187 - lr: 0.0010\nEpoch 13/100\n20/20 [==============================] - 20s 1s/step - loss: 1.2886 - accuracy: 0.4234 - val_loss: 1.3329 - val_accuracy: 0.4625 - lr: 0.0010\nEpoch 14/100\n20/20 [==============================] - 20s 1s/step - loss: 1.2568 - accuracy: 0.4328 - val_loss: 1.3229 - val_accuracy: 0.4375 - lr: 0.0010\nEpoch 15/100\n20/20 [==============================] - 20s 992ms/step - loss: 1.1969 - accuracy: 0.4594 - val_loss: 1.3739 - val_accuracy: 0.4688 - lr: 0.0010\nEpoch 16/100\n20/20 [==============================] - 19s 973ms/step - loss: 1.1901 - accuracy: 0.4797 - val_loss: 1.3317 - val_accuracy: 0.4688 - lr: 0.0010\nEpoch 17/100\n20/20 [==============================] - 20s 1s/step - loss: 1.1722 - accuracy: 0.4906 - val_loss: 1.2869 - val_accuracy: 0.4375 - lr: 0.0010\nEpoch 18/100\n20/20 [==============================] - 20s 1s/step - loss: 1.1618 - accuracy: 0.4891 - val_loss: 1.3497 - val_accuracy: 0.4750 - lr: 0.0010\nEpoch 19/100\n20/20 [==============================] - 20s 1s/step - loss: 1.1271 - accuracy: 0.5188 - val_loss: 1.2313 - val_accuracy: 0.4812 - lr: 0.0010\nEpoch 20/100\n20/20 [==============================] - 20s 1s/step - loss: 1.1300 - accuracy: 0.5344 - val_loss: 1.2551 - val_accuracy: 0.5125 - lr: 0.0010\nEpoch 21/100\n20/20 [==============================] - 19s 972ms/step - loss: 1.1059 - accuracy: 0.5281 - val_loss: 1.2984 - val_accuracy: 0.4750 - lr: 0.0010\nEpoch 22/100\n20/20 [==============================] - 20s 988ms/step - loss: 1.1500 - accuracy: 0.5109 - val_loss: 1.2476 - val_accuracy: 0.4500 - lr: 0.0010\nEpoch 23/100\n20/20 [==============================] - 20s 1s/step - loss: 1.1096 - accuracy: 0.4984 - val_loss: 1.2135 - val_accuracy: 0.4812 - lr: 0.0010\nEpoch 24/100\n20/20 [==============================] - 19s 977ms/step - loss: 1.0620 - accuracy: 0.5219 - val_loss: 1.2136 - val_accuracy: 0.5188 - lr: 0.0010\nEpoch 25/100\n20/20 [==============================] - 20s 1s/step - loss: 1.1240 - accuracy: 0.4969 - val_loss: 1.1889 - val_accuracy: 0.4875 - lr: 0.0010\nEpoch 26/100\n20/20 [==============================] - 20s 995ms/step - loss: 1.0898 - accuracy: 0.5094 - val_loss: 1.1842 - val_accuracy: 0.4938 - lr: 0.0010\nEpoch 27/100\n20/20 [==============================] - 19s 968ms/step - loss: 1.0446 - accuracy: 0.5281 - val_loss: 1.1409 - val_accuracy: 0.4875 - lr: 0.0010\nEpoch 28/100\n20/20 [==============================] - 20s 1s/step - loss: 1.0492 - accuracy: 0.5359 - val_loss: 1.2025 - val_accuracy: 0.5188 - lr: 0.0010\nEpoch 29/100\n20/20 [==============================] - 20s 991ms/step - loss: 1.0237 - accuracy: 0.5453 - val_loss: 1.2336 - val_accuracy: 0.5063 - lr: 0.0010\nEpoch 30/100\n20/20 [==============================] - 20s 1s/step - loss: 1.0737 - accuracy: 0.5578 - val_loss: 1.1677 - val_accuracy: 0.5000 - lr: 0.0010\nEpoch 31/100\n20/20 [==============================] - 20s 978ms/step - loss: 1.0774 - accuracy: 0.5484 - val_loss: 1.1471 - val_accuracy: 0.5063 - lr: 0.0010\nEpoch 32/100\n20/20 [==============================] - 20s 984ms/step - loss: 0.9965 - accuracy: 0.5906 - val_loss: 1.0999 - val_accuracy: 0.6313 - lr: 0.0010\nEpoch 33/100\n20/20 [==============================] - 20s 994ms/step - loss: 0.9933 - accuracy: 0.6016 - val_loss: 1.1148 - val_accuracy: 0.5125 - lr: 0.0010\nEpoch 34/100\n20/20 [==============================] - 20s 982ms/step - loss: 0.9392 - accuracy: 0.6203 - val_loss: 1.1170 - val_accuracy: 0.5437 - lr: 0.0010\nEpoch 35/100\n20/20 [==============================] - 19s 953ms/step - loss: 1.4304 - accuracy: 0.5000 - val_loss: 1.3188 - val_accuracy: 0.5312 - lr: 0.0010\nEpoch 36/100\n20/20 [==============================] - 20s 1s/step - loss: 1.2330 - accuracy: 0.4688 - val_loss: 1.2730 - val_accuracy: 0.3562 - lr: 0.0010\nEpoch 37/100\n20/20 [==============================] - 19s 956ms/step - loss: 1.2034 - accuracy: 0.4625 - val_loss: 1.2040 - val_accuracy: 0.5000 - lr: 0.0010\nEpoch 38/100\n20/20 [==============================] - 20s 979ms/step - loss: 1.1406 - accuracy: 0.5000 - val_loss: 1.1852 - val_accuracy: 0.4875 - lr: 5.0000e-05\n7/7 [==============================] - 2s 174ms/step - loss: 1.0059 - accuracy: 0.6750\nTest loss: 1.0059\nTest accuracy: 0.6750\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Implement all the steps ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# Generate synthetic training data\nnum_samples = 1000\ninput_shape = (1125, 1)\n\n# Define the LSTM-based model\nmodel = Sequential([\n    LSTM(256, input_shape=input_shape, return_sequences=True),\n    LSTM(256),\n    Dense(512, activation='relu'),\n    Dropout(0.2),\n    Dense(256, activation='relu'),\n    Dropout(0.2),\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Define callbacks\nlr_callback = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=3,\n    min_lr=1e-6\n)\n\ncheckpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n\n# Train the model\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_val, y_val),\n    epochs=100,\n    batch_size=32,\n    callbacks=[lr_callback, checkpoint_callback, early_stopping_callback]\n)\n\n# Load the best model\nbest_model = tf.keras.models.load_model('best_model.h5')\n\n# Evaluate the model on the test set\nloss, accuracy = best_model.evaluate(X_test, y_test)\n\nprint(f\"Test loss: {loss:.4f}\")\nprint(f\"Test accuracy: {accuracy:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}